# Awesome-Efficient-Reasoning-LLMs

## News ðŸ“¢

- **March 2025**: We released our survey paper "[Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models](https://arxiv.org/abs/2503.16419)
". Welcome! We appreciate your contributions of new papers and pull requests.

- Last Update: March 2025.
- Keep Updated...

## Section I:  RL with Length Reward Design

* Demystifying Long Chain-of-Thought Reasoning in LLMs 
* O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning 
* Kimi k1.5: Scaling Reinforcement Learning with LLMs
* Training Language Models to Reason Efficiently
* L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning
* DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models
* Optimizing Test-Time Compute via Meta Reinforcement Fine-Tuning

## Section II: SFT with Variable-Length CoT Data

* TokenSkip: Controllable Chain-of-Thought Compression in LLMs
* C3oT: Generating Shorter Chain-of-Thought without Compromising Effectiveness
* CoT-Valve: Length-Compressible Chain-of-Thought Tuning
* Self-Training Elicits Concise Reasoning in Large Language Models
* Distilling System 2 into System 1
* Can Language Models Learn to Skip Steps?
* Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought Reasoning in Large Language Models

## Section III: Compressing Reasoning Steps into Fewer Latent Representation

* Training Large Language Models to Reason in a Continuous Latent Space
* Compressed Chain of Thought: Efficient Reasoning through Dense Representations
* Efficient Reasoning with Hidden Thinking (MLLM)
* SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs
* Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning
* Reasoning with Latent Thoughts: On the Power of Looped Transformers
* CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation

## Section IV: Dynamic Reasoning Paradigm during Inference

* Efficiently Serving LLM Reasoning Programs with Certaindex 
* When More is Less: Understanding Chain-of-Thought Length in LLMs 
* Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching
* Reward-Guided Speculative Decoding for Efficient LLM Reasoning
* Fast Best-of-N Decoding via Speculative Rejection
* FastMCTS: A Simple Sampling Strategy for Data Synthesis
* Dynamic Parallel Tree Search for Efficient LLM Reasoning
* Sampling-Efficient Test-Time Scaling: Self-Estimating the Best-of-N Sampling in Early Decoding
* LightThinker: Thinking Step-by-Step Compression
* InftyThink: Breaking the Length Limits of Long-Context Reasoning in Large Language Models
  
## Section V: Prompt-Guided Efficient Reasoning

* Token-Budget-Aware LLM Reasoning 
* Chain of Draft: Thinking Faster by Writing Less
* How Well do LLMs Compress Their Own Chain-of-Thought? A Token Complexity Approach
* The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models

## Section VI: Prompts Attribute-Driven Reasoning Routing

* Claude 3.7 Sonnet and Claude Code
* Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching

## Section VII: Reasoning Abilities via Efficient Training Data and Model Compression

* LIMO: Less is More for Reasoning
* s1: Simple test-time scaling
* S2R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning
* Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and Beyond
* Small Models Struggle to Learn from Strong Reasoners
* Towards Reasoning Ability of Small Language Models
* Mixed Distillation Helps Smaller Language Models Reason Better
* Small language models need strong verifiers to self-correct reasoning
* Teaching Small Language Models Reasoning through Counterfactual Distillation
* Improving Mathematical Reasoning Capabilities of Small Language Models via Feedback-Driven Distillation
* Probe then retrieve and reason: Distilling probing and reasoning capabilities into smaller language models
* Distilling Reasoning Ability from Large Language Models with Adaptive Thinking
* SKIntern: Internalizing Symbolic Knowledge for Distilling Better CoT Capabilities into Small Language Models
  
## Section VIII: Evaluation and Benchmark
* Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling 
* The Danger of Overthinking: Examining the Reasoning-Action Dilemma in
Agentic Tasks
* Inference-Time Computations for LLM Reasoning and Planning: A Benchmark and Insights

